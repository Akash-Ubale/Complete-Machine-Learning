{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Clustering\n",
    "\n",
    "_A good cluster will have:_\n",
    "* High inter-class similarity, and \n",
    "* Low intraclass similarity\n",
    "\n",
    "#### Aspects of cluster validation\n",
    "\n",
    "* **External:** Compare your cluster to the ground truth.\n",
    "* **Internal:** Evaluating the cluster without reference to external data.\n",
    "* **Reliability:** The clusters are not formed by chance(randomly)- some statistical framework can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_A good cluster will have:_\n",
    "* High inter-class similarity, and \n",
    "* Low intraclass similarity\n",
    "\n",
    "#### Aspects of cluster validation\n",
    "\n",
    "* **External:** Compare your cluster to the ground truth.\n",
    "* **Internal:** Evaluating the cluster without reference to external data.\n",
    "\n",
    "        1. External Measures\n",
    "            1.1. Rand Index\n",
    "            1.2. Jaccard Coefficient\n",
    "            \n",
    "        2. Internal Measures.\n",
    "            2.1. Compactness - WCSS\n",
    "            2.2. Separation - BCSS\n",
    "            2.3. Silhoeutte coefficient\n",
    "            2.4. Dunn index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. External Measures:\n",
    "\n",
    "### 1.1. $$  Rand Index = \\frac{Total Agree}{Total}=\\frac{(SS+DD)}{(SS+DD+DS+SD)}$$\n",
    "\n",
    "The disadvantage of this is that it could be dominated by DD.\n",
    "\n",
    "**Why so ?** - Because the probability of two points being in different clusters is higher.\n",
    "\n",
    "Hence we consider **Jaccard Coefficient.**\n",
    "\n",
    "### 1.2. $$Jaccard Coefficient=\\frac{ SS}{(SS+SD+DS)}$$\n",
    "\n",
    "Where,\n",
    "\n",
    "N: Number of objects in the data\n",
    "\n",
    "P: {${P_1,P_2,…,P_m}$} the set of ground truth clusters\n",
    "\n",
    "C: {${C_1,C_2,…C_n}$} the set of clusters formed by our algorithm\n",
    "\n",
    "The Incidence Matrix : N $\\times$ N matrix\n",
    "\n",
    "$O_i$ = a point in $i^{th}$ Cluster.\n",
    "\n",
    "$O_j$ = a point in $j^{th}$ Cluster.\n",
    "\n",
    "$P_{ij} = 1$ if both the points $O_i$ and $O_j$ belong to the same cluster in the Ground Truth else $P_{ij}=0$ \n",
    "\n",
    "$C_{ij} =1$ if both the points $O_i$ and $O_j$ belong to the same cluster in Our Algorithm else $C_{ij}=0$ \n",
    "\n",
    "Now there can be the following scenarios:\n",
    "1.\t$C_{ij} = P_{ij}=1$ $\\Rightarrow$ both the points belong to the same cluster for both our algorithm and ground truth(Agree)--- **SS**\n",
    "2.\t$C_{ij} = P_{ij}=0$ $\\Rightarrow$ both the points don’t belong to the same cluster for both our algorithm and ground truth(Agree)--- **DD**\n",
    "3.\t$C_{ij} = 1 but P_{ij}=0$ $\\Rightarrow$ The points belong in the same cluster for our algorithm but in different clusters for the ground truth (Disagree)---- **SD**\n",
    "4.\t$C_{ij} = 0 but P_{ij}=1$ $\\Rightarrow$ The points don’t belong in the same cluster for our algorithm but in same clusters for the ground truth (Disagree)----**DS**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"confusion_metrix.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"Rand Index: %0.3f\"\n",
    "      % metrics.adjusted_rand_score(labels_true, labels))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "metrics.jaccard_similarity_score(labels_true, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A higher value of Rand Index and Jaccard's coefficient mean that the clusters generated by our algorithm mostly agree to the ground truth. i.e. our algorithm is performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Internal Measures\n",
    "\n",
    "These are the methods used to measure the quality of clusters without external references. There are two aspects to it.\n",
    "\n",
    "* **Compactness:** How closely the objects in the same cluster are related to each other. It is the within-cluster sum of squared distances. It is the same metric that we used to calculate for the K-Means algorithm.\n",
    "### 2.1. $$ WCSS = \\sum \\sum (x-m_i)^2 $$\n",
    "\n",
    "* **Separation:** How different the objects in different clusters are and how distinct a well-separated cluster is from other clusters. It is  'Between-clusters sum of squared distances'.  \n",
    "### 2.2. $$ BCSS=\\sum C_i(m-m_i)^2 $$\n",
    "\n",
    "Where $C_i$ is the size of the individual cluster and m is the centroid of all the data points.\n",
    "\n",
    "**Note:** BCSS + WCSS is always a constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Silhouette coefficient \n",
    "\n",
    "The silhouette analysis measures how well our clustering algorithm is performing.\n",
    "\n",
    "$$ SC=\\frac{1}{N} \\sum S(i) $$\n",
    "\n",
    "Where, $S(i)$  = Silhouette width of the individual observation.\n",
    "\n",
    "### $$ S(i) = \\frac{b(i) - a(i)}{max[a(i), b(i)]} $$\n",
    "\n",
    "worst -1 > S(i) > +1 Best\n",
    "\n",
    "$i$ = is an individual observation.\n",
    "\n",
    "$a(i)$  = is the avarage distance of $i$ from all the other points in the same cluster \n",
    "\n",
    "$b(i)$ = is the average distance of $i$ from its nearest neighbor cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally $a(i) << b(i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good explanation https://www.youtube.com/watch?v=AtxQ0rvdQIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also identify outliers using silhouette Graph. the points havinh silhouette score lesser than _'0'_  are outliers.\n",
    "\n",
    "The silhouette Graph can also be used to decide the optimum no. of clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Dunn index\n",
    "\n",
    "The Dunn index is another internal clustering validation measure\n",
    "\n",
    "$$ Dunn. Index = \\frac{Min. Separation}{Max. Diameter} $$\n",
    "\n",
    "where, \n",
    "\n",
    "Max. Diameter =  The maximum distance between Clusters.\n",
    "\n",
    "Min. Separation = The Minimum separation within a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
